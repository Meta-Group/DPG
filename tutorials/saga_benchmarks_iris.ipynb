{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DPGExplainer Saga Benchmarks — Episode 1: Iris\n",
    "\n",
    "A practitioner-friendly walkthrough of Decision Predicate Graphs (DPG) using the classic Iris dataset. We train a small Random Forest (RF), build a DPG to map the model’s global behavior using Explainable AI (XAI), and interpret three key properties to explain the model: Local Reaching Centrality (LRC), Betweenness Centrality (BC), and node communities.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. What is Explainable AI (XAI)\n",
    "Explainable AI (XAI) focuses on making model behavior understandable to people. It helps answer questions like why a prediction was made, what features mattered most, and whether the model behaves as intended.\n",
    "\n",
    "Common motivations for XAI include:\n",
    "- Explain to justify: Provide evidence for decisions in high-stakes contexts.\n",
    "- Explain to discover: Surface patterns, biases, or unexpected signals in the data.\n",
    "- Explain to improve: Debug models, features, and data issues.\n",
    "- Explain to control: Support monitoring, governance, and compliance.\n",
    "\n",
    "XAI methods are often grouped into:\n",
    "- Global explanations: Summarize how the model behaves overall.\n",
    "- Local explanations: Explain a single prediction or a small region of the feature space.\n",
    "\n",
    "SHAP is a popular local method, while DPG provides a global view by turning an ensemble into a predicate graph and analyzing its structure.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Why DPG (in one minute)\n",
    "Tree ensembles, such as RF, can be accurate but hard to interpret globally. DPG converts the ensemble into a graph where:\n",
    "- Nodes are predicates like `petal length <= 2.45`, in the iris case.\n",
    "- Edges capture how often training samples traverse those predicates\n",
    "- Metrics quantify how predicates structure the model’s global reasoning\n",
    "\n",
    "This gives a global map of decision logic and allows the use of graph metrics to capture the model’s rationale.\n",
    "\n",
    "In the next steps, we create a Random Forest model of the Iris dataset and explain it with DPG.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Setup (Iris + Random Forest + DPG)\n",
    "\n",
    "We first train a baseline Random Forest, then inspect pairwise feature/class structure with a pair plot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a9c1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --force-reinstall --no-deps git+https://github.com/Meta-Group/DPG.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from dpg import DPGExplainer\n",
    "\n",
    "iris = load_iris(as_frame=True)\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=27, stratify=y\n",
    ")\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=10, random_state=27)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "ConfusionMatrixDisplay(cm, display_labels=iris.target_names).plot()\n",
    "print(classification_report(y_test, y_pred, target_names=iris.target_names))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Pair Plot (All Features by Class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "pair_df = X.copy()\n",
    "pair_df[\"class_name\"] = y.map(lambda i: iris.target_names[i])\n",
    "\n",
    "sns.pairplot(\n",
    "    pair_df,\n",
    "    hue=\"class_name\",\n",
    "    diag_kind=\"kde\",\n",
    "    corner=True,\n",
    "    plot_kws={\"alpha\": 0.6, \"s\": 28, \"edgecolor\": \"none\"},\n",
    ")\n",
    "plt.suptitle(\"Iris pair plot by class\", y=1.02)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Extracting DPG from RF\n",
    "\n",
    "Next, we extract the DPG from our RF model. The parameters `feature_names` and `target_names` provide readable output for the mapped scenarios.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = DPGExplainer(\n",
    "    model=model,\n",
    "    feature_names=X.columns,\n",
    "    target_names=iris.target_names.tolist(),\n",
    "    config_file=\"config.yaml\",  # optional if present\n",
    ")\n",
    "\n",
    "explanation = explainer.explain_global(\n",
    "    X.values,\n",
    "    communities=True,\n",
    "    community_threshold=0.2,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Read the DPG Metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation.node_metrics.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Local Reaching Centrality (LRC)**\n",
    "- High LRC nodes can reach many other nodes downstream.\n",
    "- These predicates often act early, framing large portions of the model’s logic.\n",
    "\n",
    "**Betweenness Centrality (BC)**\n",
    "- High BC nodes lie on many shortest paths between other nodes.\n",
    "- These predicates are “bottlenecks” that connect major decision flows.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Compare Top LRC Predicates vs Random Forest Importance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "def parse_predicate_parts(label: str):\n",
    "    m = re.search(r\"(.+?)\\s*(<=|>)\\s*([-+]?\\d*\\.?\\d+(?:[eE][-+]?\\d+)?)\", str(label))\n",
    "    if not m:\n",
    "        return None\n",
    "    feature = m.group(1).strip()\n",
    "    op = m.group(2)\n",
    "    threshold = float(m.group(3))\n",
    "    return feature, op, threshold\n",
    "\n",
    "\n",
    "def parse_feature_from_predicate(label: str) -> str:\n",
    "    parts = parse_predicate_parts(label)\n",
    "    return parts[0] if parts else str(label)\n",
    "\n",
    "\n",
    "def lrc_predicate_scores(explanation, top_k=10):\n",
    "    nm = explanation.node_metrics.copy()\n",
    "    nm = nm[nm[\"Label\"].str.contains(r\"(<=|>)\", regex=True, na=False)].copy()\n",
    "    nm = nm.sort_values(\"Local reaching centrality\", ascending=False).head(top_k)\n",
    "\n",
    "    rows = []\n",
    "    for _, r in nm.iterrows():\n",
    "        parsed = parse_predicate_parts(r[\"Label\"])\n",
    "        if not parsed:\n",
    "            continue\n",
    "        feature, op, threshold = parsed\n",
    "        rows.append({\n",
    "            \"predicate\": str(r[\"Label\"]),\n",
    "            \"feature\": feature,\n",
    "            \"op\": op,\n",
    "            \"threshold\": threshold,\n",
    "            \"lrc\": float(r[\"Local reaching centrality\"]),\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "def _feature_color_map(features):\n",
    "    unique = list(dict.fromkeys(features))\n",
    "    cmap = plt.cm.tab20\n",
    "    if len(unique) <= 1:\n",
    "        return {unique[0]: cmap(0)} if unique else {}\n",
    "    return {f: cmap(i / (len(unique) - 1)) for i, f in enumerate(unique)}\n",
    "\n",
    "\n",
    "def plot_lrc_vs_rf_importance(explanation, model, X_df, top_k=10, dataset_name='Iris'):\n",
    "    top_lrc = lrc_predicate_scores(explanation, top_k=top_k).copy()\n",
    "\n",
    "    top_rf = (\n",
    "        pd.DataFrame({\n",
    "            \"feature\": list(getattr(model, \"feature_names_in_\", X_df.columns)),\n",
    "            \"rf_importance\": model.feature_importances_.astype(float),\n",
    "        })\n",
    "        .sort_values(\"rf_importance\", ascending=False)\n",
    "        .head(top_k)\n",
    "    )\n",
    "\n",
    "    # Sort ascending for readable horizontal bars\n",
    "    top_lrc_plot = top_lrc.sort_values(\"lrc\", ascending=True)\n",
    "    top_rf_plot = top_rf.sort_values(\"rf_importance\", ascending=True)\n",
    "\n",
    "    # Keep feature colors consistent across both plots\n",
    "    all_features = top_lrc_plot[\"feature\"].tolist() + top_rf_plot[\"feature\"].tolist()\n",
    "    feature_to_color = _feature_color_map(all_features)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, max(5, top_k * 0.45)))\n",
    "\n",
    "    axes[0].barh(\n",
    "        top_lrc_plot[\"predicate\"],\n",
    "        top_lrc_plot[\"lrc\"],\n",
    "        color=[feature_to_color[f] for f in top_lrc_plot[\"feature\"]],\n",
    "        edgecolor=\"black\",\n",
    "        linewidth=0.4,\n",
    "    )\n",
    "    axes[0].set_title(f\"{dataset_name}: Top {top_k} LRC predicates\")\n",
    "    axes[0].set_xlabel(\"Local Reaching Centrality\")\n",
    "    axes[0].set_ylabel(\"Predicate\")\n",
    "\n",
    "    axes[1].barh(\n",
    "        top_rf_plot[\"feature\"],\n",
    "        top_rf_plot[\"rf_importance\"],\n",
    "        color=[feature_to_color[f] for f in top_rf_plot[\"feature\"]],\n",
    "        edgecolor=\"black\",\n",
    "        linewidth=0.4,\n",
    "    )\n",
    "    axes[1].set_title(f\"{dataset_name}: Top {top_k} RF feature importances\")\n",
    "    axes[1].set_xlabel(\"Random Forest feature importance\")\n",
    "    axes[1].set_ylabel(\"Feature\")\n",
    "\n",
    "    legend_features = list(dict.fromkeys(all_features))\n",
    "    legend_handles = [\n",
    "        plt.Line2D([0], [0], marker='s', color='w', label=f,\n",
    "                   markerfacecolor=feature_to_color[f], markeredgecolor='black', markersize=8)\n",
    "        for f in legend_features\n",
    "    ]\n",
    "    fig.legend(handles=legend_handles, title=\"Feature colors\",\n",
    "               loc=\"lower center\", ncol=min(4, max(1, len(legend_handles))), frameon=True)\n",
    "\n",
    "    plt.tight_layout(rect=(0, 0.08, 1, 1))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_top_lrc_predicate_splits(explanation, X_df, y, top_predicates=5, top_features=2, dataset_name='Iris'):\n",
    "    top_lrc = lrc_predicate_scores(explanation, top_k=max(top_predicates, 10)).copy()\n",
    "    top5 = top_lrc.sort_values(\"lrc\", ascending=False).head(top_predicates).copy()\n",
    "\n",
    "    # Select top-2 LRC features using cumulative LRC contribution\n",
    "    feature_rank = (\n",
    "        top_lrc.groupby(\"feature\", as_index=False)[\"lrc\"].sum()\n",
    "        .sort_values(\"lrc\", ascending=False)\n",
    "        .head(top_features)\n",
    "    )\n",
    "    selected_features = feature_rank[\"feature\"].tolist()\n",
    "    if len(selected_features) < 2:\n",
    "        print(f\"{dataset_name}: not enough LRC features to build a 2D split plot.\")\n",
    "        return\n",
    "\n",
    "    fx, fy = selected_features[0], selected_features[1]\n",
    "    if fx not in X_df.columns or fy not in X_df.columns:\n",
    "        print(f\"{dataset_name}: selected LRC features not present in input dataframe columns.\")\n",
    "        return\n",
    "\n",
    "    # Lines from top-5 predicates only, restricted to top-2 selected features\n",
    "    split_rows = top5[top5[\"feature\"].isin([fx, fy])].copy()\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "    sc = ax.scatter(\n",
    "        X_df[fx],\n",
    "        X_df[fy],\n",
    "        c=y,\n",
    "        cmap='viridis',\n",
    "        s=36,\n",
    "        alpha=0.75,\n",
    "        edgecolor='white',\n",
    "        linewidth=0.5,\n",
    "    )\n",
    "\n",
    "    # Color by feature to keep consistency with section colors\n",
    "    feature_to_color = _feature_color_map([fx, fy])\n",
    "\n",
    "    line_labels_seen = set()\n",
    "    for _, r in split_rows.iterrows():\n",
    "        f, op, thr, score = r[\"feature\"], r[\"op\"], r[\"threshold\"], r[\"lrc\"]\n",
    "        if f == fx:\n",
    "            ls = '--' if op == '<=' else '-'\n",
    "            label = f\"{f} {op} {thr:.2f} (LRC={score:.3f})\"\n",
    "            ax.axvline(\n",
    "                thr,\n",
    "                color=feature_to_color[f],\n",
    "                linestyle=ls,\n",
    "                linewidth=2,\n",
    "                alpha=0.9,\n",
    "                label=label if label not in line_labels_seen else None,\n",
    "            )\n",
    "            line_labels_seen.add(label)\n",
    "        elif f == fy:\n",
    "            ls = '--' if op == '<=' else '-'\n",
    "            label = f\"{f} {op} {thr:.2f} (LRC={score:.3f})\"\n",
    "            ax.axhline(\n",
    "                thr,\n",
    "                color=feature_to_color[f],\n",
    "                linestyle=ls,\n",
    "                linewidth=2,\n",
    "                alpha=0.9,\n",
    "                label=label if label not in line_labels_seen else None,\n",
    "            )\n",
    "            line_labels_seen.add(label)\n",
    "\n",
    "    ax.set_title(\n",
    "        f\"{dataset_name}: Top-{top_predicates} LRC predicate splits on top-2 LRC features\"\n",
    "    )\n",
    "    ax.set_xlabel(fx)\n",
    "    ax.set_ylabel(fy)\n",
    "\n",
    "    # class legend + predicate legend\n",
    "    cbar = fig.colorbar(sc, ax=ax, fraction=0.046, pad=0.04)\n",
    "    cbar.set_label('Class id')\n",
    "\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    if handles:\n",
    "        ax.legend(handles, labels, title='Top LRC predicate lines', loc='best', fontsize=8)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_lrc_vs_rf_importance(explanation, model, X, top_k=10, dataset_name='Iris')\n",
    "plot_top_lrc_predicate_splits(explanation, X, y, top_predicates=5, top_features=2, dataset_name='Iris')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9ae106",
   "metadata": {},
   "source": [
    "### Optional: inspect top-10 LRC and RF tables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_lrc = lrc_predicate_scores(explanation, top_k=10)\n",
    "top_rf = (\n",
    "    pd.DataFrame({\n",
    "        \"feature\": list(getattr(model, \"feature_names_in_\", X.columns)),\n",
    "        \"rf_importance\": model.feature_importances_.astype(float),\n",
    "    })\n",
    "    .sort_values(\"rf_importance\", ascending=False)\n",
    "    .head(10)\n",
    ")\n",
    "\n",
    "top_lrc\n",
    "top_rf\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretation guide:\n",
    "- If a predicate has **high LRC**, it likely sets an early rule that shapes many later decisions.\n",
    "- If a feature has **high RF importance**, it contributes strongly to split quality across the forest.\n",
    "- Compare overlap: when high-LRC predicates and high-RF features agree, the global graph and model-level importance tell a consistent story.\n",
    "\n",
    "### BC analysis\n",
    "This notebook includes a BC bottleneck cloud in PCA space (Section 7).\n",
    "A full BC ranking-focused analysis will be covered in a separate session/notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Show BC Bottleneck Cloud in PCA Space\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def bc_weights_from_explanation(explanation, X_df, top_k=10):\n",
    "    nm = explanation.node_metrics.copy()\n",
    "    nm = nm[nm[\"Label\"].str.contains(r\"(<=|>)\", regex=True, na=False)].copy()\n",
    "    top_bc = nm.sort_values(\"Betweenness centrality\", ascending=False).head(top_k)\n",
    "\n",
    "    weights = np.zeros(len(X_df), dtype=float)\n",
    "\n",
    "    for _, row in top_bc.iterrows():\n",
    "        parsed = re.search(r\"(.+?)\\s*(<=|>)\\s*([-+]?\\d*\\.?\\d+(?:[eE][-+]?\\d+)?)\", str(row[\"Label\"]))\n",
    "        if not parsed:\n",
    "            continue\n",
    "        feature = parsed.group(1).strip()\n",
    "        op = parsed.group(2)\n",
    "        threshold = float(parsed.group(3))\n",
    "        if feature not in X_df.columns:\n",
    "            continue\n",
    "\n",
    "        vals = X_df[feature].values\n",
    "        vals = np.where(np.isfinite(vals), vals, np.nan)\n",
    "        if op == '<=':\n",
    "            weights += (vals <= threshold)\n",
    "        else:\n",
    "            weights += (vals > threshold)\n",
    "\n",
    "    if weights.max() > 0:\n",
    "        weights = weights / weights.max()\n",
    "    return weights\n",
    "\n",
    "\n",
    "def pca_kde_plot(X_df, y, weights, title):\n",
    "    X_clean = X_df.replace([np.inf, -np.inf], np.nan)\n",
    "    valid_mask = ~X_clean.isna().any(axis=1)\n",
    "    X_valid = X_clean[valid_mask]\n",
    "    y_valid = y[valid_mask]\n",
    "    w_valid = weights[valid_mask]\n",
    "\n",
    "    pca = PCA(n_components=2, random_state=27)\n",
    "    X_pca = pca.fit_transform(X_valid)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(7, 5), facecolor='white')\n",
    "    ax.set_facecolor('#f6d6d6')\n",
    "\n",
    "    kde = sns.kdeplot(\n",
    "        x=X_pca[:, 0],\n",
    "        y=X_pca[:, 1],\n",
    "        weights=w_valid,\n",
    "        fill=True,\n",
    "        levels=25,\n",
    "        cmap='turbo_r',\n",
    "        alpha=0.9,\n",
    "        thresh=0.0,\n",
    "        bw_adjust=1.15,\n",
    "        ax=ax,\n",
    "    )\n",
    "\n",
    "    ax.scatter(\n",
    "        X_pca[:, 0],\n",
    "        X_pca[:, 1],\n",
    "        c=y_valid,\n",
    "        cmap='viridis',\n",
    "        s=22,\n",
    "        alpha=0.5,\n",
    "        edgecolor='k',\n",
    "        linewidth=0.4,\n",
    "    )\n",
    "\n",
    "    cbar = fig.colorbar(kde.collections[0], ax=ax, fraction=0.046, pad=0.04)\n",
    "    cbar.set_label('Prediction confidence (red = higher, blue = lower)')\n",
    "\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('PCA 1')\n",
    "    ax.set_ylabel('PCA 2')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "weights = bc_weights_from_explanation(explanation, X, top_k=10)\n",
    "pca_kde_plot(X, y, weights, 'Iris: BC Bottleneck Cloud in PCA Space')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Communities (Decision Themes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation.communities.keys()\n",
    "explanation.communities.get(\"Communities\", [])[:3]\n",
    "\n",
    "run_name = \"iris_dpg\"\n",
    "explainer.plot(run_name, explanation, save_dir=\"results\", class_flag=True, export_pdf=True)\n",
    "explainer.plot_communities(run_name, explanation, save_dir=\"results\", class_flag=True, export_pdf=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. What to Say in the Story\n",
    "Use these three points for a quick practitioner summary:\n",
    "- **LRC:** Which predicate most strongly frames the model’s logic?\n",
    "- **BC:** Which predicate acts as a bottleneck between key decision paths?\n",
    "- **Communities:** Which predicate groups define the “themes” of each class?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Episode\n",
    "We will move to another scikit-learn benchmark dataset.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
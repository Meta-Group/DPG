{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DPGExplainer Saga Benchmarks \u2014 Episode 1: Iris\n",
    "\n",
    "A practitioner-friendly walkthrough of Decision Predicate Graphs (DPG) using the classic Iris dataset. We train a small Random Forest (RF), build a DPG to map the model\u2019s global behavior using Explainable AI (XAI), and interpret three key properties to explain the model: Local Reaching Centrality (LRC), Betweenness Centrality (BC), and node communities.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. What is Explainable AI (XAI)\n",
    "Explainable AI (XAI) focuses on making model behavior understandable to people. It helps answer questions like why a prediction was made, what features mattered most, and whether the model behaves as intended.\n",
    "\n",
    "Common motivations for XAI include:\n",
    "- Explain to justify: Provide evidence for decisions in high-stakes contexts.\n",
    "- Explain to discover: Surface patterns, biases, or unexpected signals in the data.\n",
    "- Explain to improve: Debug models, features, and data issues.\n",
    "- Explain to control: Support monitoring, governance, and compliance.\n",
    "\n",
    "XAI methods are often grouped into:\n",
    "- Global explanations: Summarize how the model behaves overall.\n",
    "- Local explanations: Explain a single prediction or a small region of the feature space.\n",
    "\n",
    "SHAP is a popular local method, while DPG provides a global view by turning an ensemble into a predicate graph and analyzing its structure.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Why DPG (in one minute)\n",
    "Tree ensembles, such as RF, can be accurate but hard to interpret globally. DPG converts the ensemble into a graph where:\n",
    "- Nodes are predicates like `petal length <= 2.45`, in the iris case.\n",
    "- Edges capture how often training samples traverse those predicates\n",
    "- Metrics quantify how predicates structure the model\u2019s global reasoning\n",
    "\n",
    "This gives a global map of decision logic and allows the use of graph metrics to capture the model\u2019s rationale.\n",
    "\n",
    "In the next steps, we create a Random Forest model of the Iris dataset and explain it with DPG.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Setup (Iris + Random Forest + DPG)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from dpg import DPGExplainer\n",
    "\n",
    "iris = load_iris(as_frame=True)\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=27, stratify=y\n",
    ")\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=10, random_state=27)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "ConfusionMatrixDisplay(cm, display_labels=iris.target_names).plot()\n",
    "print(classification_report(y_test, y_pred, target_names=iris.target_names))\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Extracting DPG from RF\n",
    "\n",
    "Next, we extract the DPG from our RF model. The parameters `feature_names` and `target_names` provide readable output for the mapped scenarios.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "explainer = DPGExplainer(\n",
    "    model=model,\n",
    "    feature_names=X.columns,\n",
    "    target_names=iris.target_names.tolist(),\n",
    "    config_file=\"config.yaml\",  # optional if present\n",
    ")\n",
    "\n",
    "explanation = explainer.explain_global(\n",
    "    X.values,\n",
    "    communities=True,\n",
    "    community_threshold=0.2,\n",
    ")\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Read the DPG Metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "explanation.node_metrics.head()\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Local Reaching Centrality (LRC)**\n",
    "- High LRC nodes can reach many other nodes downstream.\n",
    "- These predicates often act early, framing large portions of the model\u2019s logic.\n",
    "\n",
    "**Betweenness Centrality (BC)**\n",
    "- High BC nodes lie on many shortest paths between other nodes.\n",
    "- These predicates are \u201cbottlenecks\u201d that connect major decision flows.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Find the Top LRC and BC Predicates\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "explanation.node_metrics.sort_values(\n",
    "    \"Local reaching centrality\", ascending=False\n",
    ").head(10)\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "explanation.node_metrics.sort_values(\n",
    "    \"Betweenness centrality\", ascending=False\n",
    ").head(10)\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretation guide:\n",
    "- If a predicate has **high LRC**, it likely sets an early rule that shapes many later decisions.\n",
    "- If a predicate has **high BC**, it likely separates multiple alternative paths in the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Communities (Decision Themes)\n",
    "Communities group predicates that are tightly connected. For Iris, you often see groups that align with:\n",
    "- Short petal rules (often Setosa)\n",
    "- Longer petal or wider sepal rules (often Versicolor/Virginica)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "explanation.communities.keys()\n",
    "explanation.communities.get(\"Communities\", [])[:3]\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Visualize the Story\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "run_name = \"iris_dpg\"\n",
    "explainer.plot(run_name, explanation, save_dir=\"results\", class_flag=True, export_pdf=True)\n",
    "explainer.plot_communities(run_name, explanation, save_dir=\"results\", class_flag=True, export_pdf=True)\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. What to Say in the Story\n",
    "Use these three points for a quick practitioner summary:\n",
    "- **LRC:** Which predicate most strongly frames the model\u2019s logic?\n",
    "- **BC:** Which predicate acts as a bottleneck between key decision paths?\n",
    "- **Communities:** Which predicate groups define the \u201cthemes\u201d of each class?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Episode\n",
    "We will move to another scikit-learn benchmark dataset.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}